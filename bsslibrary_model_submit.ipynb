{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4e461-afcc-42a7-aa3e-b7a13e5d0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.transforms import v2\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Swinv2Model, ConvNextV2Model, AutoModel\n",
    "import timm\n",
    "from PIL import Image\n",
    "\n",
    "torch.set_float32_matmul_precision('high')  # or 'medium' | 'high'\n",
    "# os.environ['WANDB_API_KEY']='xxxxx'\n",
    "# os.environ['WANDB_MODE']='online'\n",
    "# os.environ['WANDB_PROJECT']='basslibrary240210'\n",
    "os.environ['WANDB_MODE']='offline'\n",
    "\n",
    "######## logger ########\n",
    "import sys, logging, IPython\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig( handlers=[ logging.StreamHandler(stream=sys.stdout), logging.handlers.RotatingFileHandler(filename='run.log', mode='a', maxBytes=512000, backupCount=4) ] )\n",
    "logging_fomatter = logging.Formatter( '%(asctime)s [%(levelname)-4.4s] %(message)s', datefmt='%m/%d %H:%M:%S' )\n",
    "_ = [ h.setFormatter(logging_fomatter) for h in logger.handlers ]\n",
    "logger.setLevel(logging.INFO)\n",
    "def showtraceback(self, *args, **kwargs):\n",
    "    logger.exception('-------Exception----------')\n",
    "IPython.core.interactiveshell.InteractiveShell.showtraceback = showtraceback\n",
    "logger.info('program started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c591b9-cc39-4c6a-bbaf-0dc6cb7a9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {}\n",
    "CFG['SEED'] = 42\n",
    "CFG['N_SPLIT'] = 5\n",
    "CFG['LABEL_SMOOTHING'] = 0.05\n",
    "CFG['OPTIMIZER'] = 'AdamW'\n",
    "CFG['INTERPOLATION'] = 'robidouxsharp'\n",
    "CFG['PRECISION'] = '16'\n",
    "#----------------------------------\n",
    "CFG['MODEL_NAME'] = \"timm/beitv2_large_patch16_224.in1k_ft_in22k_in1k\"\n",
    "CFG['IMG_SIZE'] = 224\n",
    "CFG['BATCH_SIZE'] = 48 ## 48//16G(ema), 14//8G memory..\n",
    "CFG['LR'] = [ 0.25e-5 * np.sqrt(CFG['BATCH_SIZE']), 1e-6 ]\n",
    "#----------------------------------\n",
    "\n",
    "######################################\n",
    "if 'IMG_TRAIN_SIZE' not in CFG:\n",
    "    CFG['IMG_TRAIN_SIZE'] = CFG['IMG_SIZE']\n",
    "logger.info(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b2954-c345-4980-95ff-06b44ea5070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "logger.info(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda15246-7d22-4fab-ab4e-1fafcc0d79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    logger.info(f'seed_everything : {seed}')\n",
    "\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6adef6-786e-41f2-a3de-16364d38d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, load_img_size, shuffle=False, transforms=None, interpolation='robidouxsharp' ):\n",
    "        self.df = pd.DataFrame({'img_path_list': img_path_list})\n",
    "        self.interpolation = interpolation\n",
    "        self.load_img_size = load_img_size\n",
    "        logger.info(f'load_img_size={load_img_size}')\n",
    "        if label_list is not None:\n",
    "            self.df['label_list'] = label_list\n",
    "        if shuffle:\n",
    "            self.df = self.df.sample(frac=1.0).reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    # numpy or PIL Image => PIL Image\n",
    "    def get_interpolated_image(self, img, new_image_size):\n",
    "        if self.interpolation == 'pil_lanczos':\n",
    "            if isinstance(img, np.ndarray ):\n",
    "                img = Image.fromarray(img)\n",
    "            return img.resize( (new_image_size, new_image_size), Image.LANCZOS )\n",
    "        elif self.interpolation == 'cv2_lanczos4':\n",
    "            if not isinstance(img, np.ndarray ):\n",
    "                img = np.array(img)\n",
    "            import cv2\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            img = cv2.resize(src, (new_image_size, new_image_size), interpolation=cv2.INTER_LANCZOS4) # 픽셀 크기 지정\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "            return Image.fromarray(img)\n",
    "        else:\n",
    "            if not isinstance(img, np.ndarray ):\n",
    "                img = np.array(img)\n",
    "            from wand import image\n",
    "            with image.Image.from_array(img) as src:\n",
    "                src.resize( new_image_size, new_image_size, filter=self.interpolation )\n",
    "                return Image.fromarray(np.array(src))\n",
    "                \n",
    "    # path => PIL Image\n",
    "    def get_image_from_index(self, index, img_size ):\n",
    "        img_path = self.df.img_path_list[index]\n",
    "        fname = img_path.replace('./','').split('.')[0] + '.png'\n",
    "        full_fname = f'img_cached/{img_size}_{self.interpolation}/{fname}'\n",
    "        if os.path.exists(full_fname):\n",
    "            img = Image.open(full_fname)\n",
    "        else:            \n",
    "            fname_path = '/'.join(full_fname.split('/')[:-1])\n",
    "            os.makedirs(fname_path, exist_ok = True)\n",
    "            img = self.get_interpolated_image(Image.open(img_path), img_size )\n",
    "            img.save( full_fname )\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.get_image_from_index( index, self.load_img_size )\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        if 'label_list' in self.df.columns:\n",
    "            label = self.df.label_list[index]\n",
    "            return { 'pixel_values': image, 'label': label }\n",
    "        else:\n",
    "            return { 'pixel_values': image }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6398c61-4e5f-4319-953f-f006ded71b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.clf = nn.LazyLinear(25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.pooler_output\n",
    "        if self.clf:\n",
    "            x = self.clf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce0e89-e2f6-44b4-9dc2-a3d4f09b2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = CFG['IMG_SIZE']\n",
    "\n",
    "train_transform_list = [\n",
    "    v2.TrivialAugmentWide(interpolation=v2.InterpolationMode.BICUBIC), \n",
    "    v2.RandomErasing(),\n",
    "    v2.Resize(size=(image_size, image_size), interpolation=v2.InterpolationMode.LANCZOS, antialias=True),\n",
    "    v2.ToImage(), v2.ToDtype( torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]\n",
    "if CFG['IMG_SIZE'] == CFG['IMG_TRAIN_SIZE']:\n",
    "    train_transform_list = [ a for a in train_transform_list if not isinstance(a, v2.Resize) ]\n",
    "train_transform = v2.Compose(train_transform_list )\n",
    "test_transform = v2.Compose( [\n",
    "    v2.ToImage(), v2.ToDtype( torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a036a5-ad79-48b9-bf49-0597315bea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    save_training = model.training\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            pixel_values = batch['pixel_values'].to(device)            \n",
    "            pred = model(pixel_values)  ## F.softmax(output) ## 의미는 없을 듯.\n",
    "            preds += pred.detach().cpu().numpy().tolist()\n",
    "    if save_training:\n",
    "        model.train()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015fa57-4d3a-49bd-a96f-8a7de2ef0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name):\n",
    "    import timm\n",
    "    from transformers import AutoModel, AutoModelForImageClassification, AutoConfig\n",
    "    \n",
    "    logger.info(f'create_model: {model_name}')\n",
    "    if '/' not in model_name:\n",
    "        model_name = 'timm/' + model_name\n",
    "    if model_name.startswith('./'):\n",
    "        import nextvit\n",
    "        model = CustomModel( timm.create_model('nextvit_large', pretrained=True, checkpoint_path=model_name) )\n",
    "    elif model_name.startswith('facebook/hiera_'):\n",
    "        from hiera import Hiera  ## pip install hiera-transformer\n",
    "        model = CustomModel( Hiera.from_pretrained(model_name) )\n",
    "    elif model_name.startswith('timm/'):\n",
    "        model = CustomModel( timm.create_model( model_name, pretrained=True ) )\n",
    "    else:\n",
    "        model = CustomModel( AutoModel.from_pretrained(model_name) )\n",
    "        \n",
    "    model.eval()\n",
    "    model( torch.rand((1,3,CFG['IMG_SIZE'],CFG['IMG_SIZE'])).type(torch.float32) ) ## initalize_lazyLinear..\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c50fb-0c64-46a4-83b1-58894bafcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "le = LabelEncoder()\n",
    "train_df['class'] = le.fit_transform(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6897a9-6dc3-46dc-8663-7a87436c12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb57d5-b76a-4e22-9e36-f792d10cf28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ckpt_df = pd.DataFrame({'fname':glob('./ckpt/*.ckpt')})\n",
    "ckpt_df['mtime'] = ckpt_df.fname.apply(lambda x: int(os.stat(x).st_mtime))\n",
    "ckpt_df['model_name'] = ckpt_df.fname.apply(lambda x: re.search(r'./ckpt/(.*?)-fold',x)[1])\n",
    "ckpt_df['img_size'] = ckpt_df.fname.apply(lambda x: int(re.search(r'patch[0-9]+_([0-9]+)', x + 'patch0_0')[1]) )\n",
    "ckpt_df['is_ema'] = ckpt_df.fname.str.endswith('ema.ckpt').astype(int)\n",
    "ckpt_df['fold_idx'] = ckpt_df.fname.apply(lambda x: int(re.search(r'fold_idx=([0-9])-',x)[1]))\n",
    "ckpt_df['val_loss'] = ckpt_df.fname.apply(lambda x: float(re.search(r'val_loss=(0\\.[0-9]+)', x)[1]) )\n",
    "ckpt_df['val_score'] = ckpt_df.fname.apply(lambda x: float(re.search(r'val_score=(0\\.[0-9]+)', x)[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5a69b-8cb4-41dd-afcf-8839e1d48e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_df.loc[ckpt_df.model_name == 'swinv2', ['model_name', 'img_size']] = ['microsoft/swinv2-large-patch4-window12-192-22k', 192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f42124-ac10-4c13-9a36-a4a99f444317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_df = ckpt_df[ (ckpt_df.img_size != 0) & (ckpt_df.is_ema == 0) ]\n",
    "ckpt_df = ckpt_df.sort_values('mtime',ascending=False).reset_index(drop=True)\n",
    "display(ckpt_df)\n",
    "ckpt_indexes = ckpt_df[ ckpt_df.fold_idx==ckpt_df.fold_idx.max() ].index[:4]\n",
    "display(ckpt_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b2dd2-dbd6-460f-8927-de28060490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "preds_score = []\n",
    "\n",
    "for ckpt_start_index in ckpt_indexes:\n",
    "    logger.info(f'{ckpt_df.fname[ckpt_start_index]} loading')\n",
    "    ## imagesize\n",
    "    CFG['IMG_SIZE'] = ckpt_df.img_size[ckpt_start_index]\n",
    "    assert CFG['IMG_SIZE'] in ( 192, 196, 224, )\n",
    "    logger.info(CFG['IMG_SIZE'])\n",
    "\n",
    "    test_dataset = CustomDataset(\n",
    "        test_df['img_path'].values, None, \n",
    "        interpolation=CFG['INTERPOLATION'], load_img_size=CFG['IMG_SIZE'],\n",
    "        shuffle=False, transforms=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE']*2, shuffle=False, num_workers=0)\n",
    "\n",
    "    model_name = ckpt_df.model_name[ckpt_start_index]\n",
    "    model = create_model(model_name)\n",
    "    if ckpt_df.is_ema[ckpt_start_index]:\n",
    "        model = torch.optim.swa_utils.AveragedModel(model)\n",
    "    #-----------------------------\n",
    "    for i in range(ckpt_start_index, ckpt_start_index + ckpt_df.fold_idx.max() + 1 ):\n",
    "        checkpoint_path = ckpt_df.fname[i]\n",
    "        logger.info(f'{checkpoint_path} loading')\n",
    "        model.load_state_dict( torch.load(checkpoint_path)['model'] )\n",
    "\n",
    "        preds_score.append( ckpt_df.val_score[i] )\n",
    "        preds.append( prediction(model, test_loader, device) )\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds_score = np.array(preds_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846da07-020f-48fa-b274-d81a59327f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 가중치 평균값..\n",
    "preds_error = (1-preds_score)  ## L1 ACC 오차인경우\n",
    "preds_error = 1-preds_error/preds_error.sum()\n",
    "preds_coef = preds_error/preds_error.sum()\n",
    "\n",
    "logger.info(f'{preds_score=}')\n",
    "logger.info(f'{preds_coef=}')\n",
    "preds2 = np.array( [ coef * preds[i] for i, coef in enumerate( preds_coef ) ] )\n",
    "preds_labels = le.inverse_transform(preds2.sum(0).argmax(-1))\n",
    "print(preds_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a04533-3736-4fb9-91e4-328e97926496",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds_labels\n",
    "from datetime import datetime\n",
    "dt_str = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "submit.to_csv(f'./basslibrary_submit_{dt_str}.csv', index=False)\n",
    "logger.info(f'./basslibrary_submit_{dt_str}.csv saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550885cf-9e3f-4910-822c-6c6b51fbdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b2c4d-2d15-423b-9d6a-20976293ae49",
   "metadata": {
    "id": "RZo9oMpITxaP"
   },
   "outputs": [],
   "source": [
    "# !python ~/send_telegram.py 'basslibrary_submit_{dt_str}.csv saved'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
