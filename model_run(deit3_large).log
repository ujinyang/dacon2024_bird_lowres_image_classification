# model_name : deit3_large_patch16_224

05/05 02:34:46 [INFO] program started
05/05 02:34:46 [INFO] {'SEED': 42, 'N_SPLIT': 5, 'LABEL_SMOOTHING': 0.05, 'OPTIMIZER': 'AdamW', 'INTERPOLATION': 'robidouxsharp', 'PRECISION': '16', 'MODEL_NAME': 'timm/deit3_large_patch16_224.fb_in22k_ft_in1k', 'IMG_SIZE': 224, 'BATCH_SIZE': 48, 'LR': [1.7320508075688774e-05, 1e-07], 'IMG_TRAIN_SIZE': 224}
05/05 02:34:46 [INFO] cuda
05/05 02:34:46 [INFO] seed_everything : 42
05/05 02:34:46 [INFO] fold_idx=0 started
05/05 02:34:47 [ERRO] Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.
05/05 02:34:55 [INFO] load_img_size=224
05/05 02:34:55 [INFO] load_img_size=224
05/05 02:34:55 [INFO] create_model: timm/deit3_large_patch16_224.fb_in22k_ft_in1k
05/05 02:34:55 [INFO] Loading pretrained weights from Hugging Face hub (timm/deit3_large_patch16_224.fb_in22k_ft_in1k)
05/05 02:34:55 [INFO] [timm/deit3_large_patch16_224.fb_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
05/05 02:34:56 [INFO] use_amp=True
05/05 02:36:18 [INFO] eps=1, lr=3.22e-05, t_loss=2.0501, v_loss=0.9961*, v_f1=0.8821*
05/05 02:37:41 [INFO] eps=1, lr=3e-05, t_loss=1.4631, v_loss=0.5641*, v_f1=0.9476*
05/05 02:39:05 [INFO] eps=1, lr=2.79e-05, t_loss=1.2172, v_loss=0.5249*, v_f1=0.9607*
05/05 02:40:29 [INFO] eps=1, lr=2.59e-05, t_loss=1.0856, v_loss=0.5070*, v_f1=0.9635*
05/05 02:41:53 [INFO] eps=2, lr=2.41e-05, t_loss=0.6190, v_loss=0.4888*, v_f1=0.9657*
05/05 02:43:17 [INFO] eps=2, lr=2.24e-05, t_loss=0.6230, v_loss=0.4828*, v_f1=0.9646 
05/05 02:44:41 [INFO] eps=2, lr=2.08e-05, t_loss=0.6186, v_loss=0.4755*, v_f1=0.9672*
05/05 02:46:04 [INFO] eps=2, lr=1.94e-05, t_loss=0.6113, v_loss=0.4683*, v_f1=0.9660 
05/05 02:47:28 [INFO] eps=3, lr=1.8e-05, t_loss=0.5680, v_loss=0.4659*, v_f1=0.9667 
05/05 02:48:52 [INFO] eps=3, lr=1.68e-05, t_loss=0.5573, v_loss=0.4622*, v_f1=0.9713*
05/05 02:50:15 [INFO] eps=3, lr=1.56e-05, t_loss=0.5564, v_loss=0.4553*, v_f1=0.9695 
05/05 02:51:39 [INFO] eps=3, lr=1.45e-05, t_loss=0.5549, v_loss=0.4563 , v_f1=0.9688 
05/05 02:53:03 [INFO] eps=4, lr=1.35e-05, t_loss=0.5283, v_loss=0.4528*, v_f1=0.9698 
05/05 02:54:27 [INFO] eps=4, lr=1.25e-05, t_loss=0.5314, v_loss=0.4472*, v_f1=0.9697 
05/05 02:55:50 [INFO] eps=4, lr=1.17e-05, t_loss=0.5271, v_loss=0.4436*, v_f1=0.9728*
05/05 02:57:14 [INFO] eps=4, lr=1.08e-05, t_loss=0.5260, v_loss=0.4417*, v_f1=0.9722 
05/05 02:58:38 [INFO] eps=5, lr=1.01e-05, t_loss=0.5089, v_loss=0.4407*, v_f1=0.9728*
05/05 03:00:01 [INFO] eps=5, lr=9.38e-06, t_loss=0.4995, v_loss=0.4418 , v_f1=0.9725 
05/05 03:01:25 [INFO] eps=5, lr=8.73e-06, t_loss=0.5041, v_loss=0.4415 , v_f1=0.9719 
05/05 03:02:48 [INFO] eps=5, lr=8.11e-06, t_loss=0.5079, v_loss=0.4391*, v_f1=0.9725 
05/05 03:04:12 [INFO] eps=6, lr=7.55e-06, t_loss=0.5050, v_loss=0.4390*, v_f1=0.9728*
05/05 03:05:36 [INFO] eps=6, lr=7.02e-06, t_loss=0.5065, v_loss=0.4386*, v_f1=0.9726 
05/05 03:06:59 [INFO] eps=6, lr=6.53e-06, t_loss=0.5017, v_loss=0.4391 , v_f1=0.9710 
05/05 03:08:22 [INFO] eps=6, lr=6.07e-06, t_loss=0.4987, v_loss=0.4376*, v_f1=0.9726 
05/05 03:09:45 [INFO] eps=7, lr=5.65e-06, t_loss=0.4865, v_loss=0.4386 , v_f1=0.9719 
05/05 03:11:07 [INFO] eps=7, lr=5.25e-06, t_loss=0.4929, v_loss=0.4366*, v_f1=0.9713 
05/05 03:12:30 [INFO] eps=7, lr=4.88e-06, t_loss=0.4887, v_loss=0.4356*, v_f1=0.9735*
05/05 03:13:52 [INFO] eps=7, lr=4.54e-06, t_loss=0.4871, v_loss=0.4352*, v_f1=0.9739*
05/05 03:15:15 [INFO] eps=8, lr=4.22e-06, t_loss=0.4697, v_loss=0.4357 , v_f1=0.9742*
05/05 03:16:38 [INFO] eps=8, lr=3.93e-06, t_loss=0.4758, v_loss=0.4347*, v_f1=0.9722 
05/05 03:18:01 [INFO] eps=8, lr=3.65e-06, t_loss=0.4788, v_loss=0.4352 , v_f1=0.9739 
05/05 03:19:23 [INFO] eps=8, lr=3.4e-06, t_loss=0.4751, v_loss=0.4360 , v_f1=0.9723 
05/05 03:20:46 [INFO] eps=9, lr=3.16e-06, t_loss=0.4759, v_loss=0.4351 , v_f1=0.9741 
05/05 03:22:10 [INFO] eps=9, lr=2.94e-06, t_loss=0.4874, v_loss=0.4350 , v_f1=0.9732 
05/05 03:23:32 [INFO] eps=9, lr=2.73e-06, t_loss=0.4885, v_loss=0.4327*, v_f1=0.9738 
05/05 03:24:55 [INFO] eps=9, lr=2.54e-06, t_loss=0.4904, v_loss=0.4328 , v_f1=0.9736 
05/05 03:26:18 [INFO] eps=10, lr=2.36e-06, t_loss=0.4770, v_loss=0.4324*, v_f1=0.9732 
05/05 03:27:41 [INFO] eps=10, lr=2.2e-06, t_loss=0.4795, v_loss=0.4317*, v_f1=0.9735 
05/05 03:29:03 [INFO] eps=10, lr=2.04e-06, t_loss=0.4785, v_loss=0.4311*, v_f1=0.9738 
05/05 03:30:26 [INFO] eps=10, lr=1.9e-06, t_loss=0.4771, v_loss=0.4310*, v_f1=0.9728 
05/05 03:31:49 [INFO] eps=11, lr=1.77e-06, t_loss=0.4797, v_loss=0.4306*, v_f1=0.9726 
05/05 03:33:13 [INFO] eps=11, lr=1.64e-06, t_loss=0.4757, v_loss=0.4312 , v_f1=0.9741 
05/05 03:34:36 [INFO] eps=11, lr=1.53e-06, t_loss=0.4752, v_loss=0.4317 , v_f1=0.9738 
05/05 03:35:59 [INFO] eps=11, lr=1.42e-06, t_loss=0.4747, v_loss=0.4308 , v_f1=0.9741 
05/05 03:37:22 [INFO] eps=12, lr=1.32e-06, t_loss=0.4740, v_loss=0.4311 , v_f1=0.9738 
05/05 03:38:45 [INFO] eps=12, lr=1.23e-06, t_loss=0.4674, v_loss=0.4314 , v_f1=0.9731 
05/05 03:40:08 [INFO] eps=12, lr=1.14e-06, t_loss=0.4664, v_loss=0.4314 , v_f1=0.9731 
05/05 03:40:08 [INFO] NO_MORE_TRAINING, best_score=0.9742
05/05 03:40:28 [INFO] EMA ::: ema_v_loss=0.4315, ema_v_f1=0.9735
05/05 03:40:29 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=0-epoch=12-val_loss=0.4315-val_score=0.9735-ema.ckpt : (ema) saved.
05/05 03:40:30 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=0-epoch=08-val_loss=0.4357-val_score=0.9742.ckpt : saved.
05/05 03:40:31 [INFO] fold_idx=0 finished
05/05 03:40:37 [INFO] fold_idx=1 started
05/05 03:40:45 [INFO] load_img_size=224
05/05 03:40:45 [INFO] load_img_size=224
05/05 03:40:45 [INFO] create_model: timm/deit3_large_patch16_224.fb_in22k_ft_in1k
05/05 03:40:45 [INFO] Loading pretrained weights from Hugging Face hub (timm/deit3_large_patch16_224.fb_in22k_ft_in1k)
05/05 03:40:45 [INFO] [timm/deit3_large_patch16_224.fb_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
05/05 03:40:45 [INFO] use_amp=True
05/05 03:42:07 [INFO] eps=1, lr=3.22e-05, t_loss=2.0247, v_loss=1.0273*, v_f1=0.8611*
05/05 03:43:30 [INFO] eps=1, lr=3e-05, t_loss=1.4751, v_loss=0.5931*, v_f1=0.9370*
05/05 03:44:53 [INFO] eps=1, lr=2.79e-05, t_loss=1.2225, v_loss=0.5432*, v_f1=0.9534*
05/05 03:46:16 [INFO] eps=1, lr=2.59e-05, t_loss=1.0920, v_loss=0.5122*, v_f1=0.9589*
05/05 03:47:39 [INFO] eps=2, lr=2.41e-05, t_loss=0.6305, v_loss=0.5031*, v_f1=0.9578 
05/05 03:49:02 [INFO] eps=2, lr=2.24e-05, t_loss=0.6240, v_loss=0.4858*, v_f1=0.9638*
05/05 03:50:25 [INFO] eps=2, lr=2.08e-05, t_loss=0.6189, v_loss=0.4809*, v_f1=0.9628 
05/05 03:51:48 [INFO] eps=2, lr=1.94e-05, t_loss=0.6165, v_loss=0.4769*, v_f1=0.9650*
05/05 03:53:12 [INFO] eps=3, lr=1.8e-05, t_loss=0.5503, v_loss=0.4672*, v_f1=0.9651*
05/05 03:54:35 [INFO] eps=3, lr=1.68e-05, t_loss=0.5547, v_loss=0.4657*, v_f1=0.9642 
05/05 03:55:58 [INFO] eps=3, lr=1.56e-05, t_loss=0.5637, v_loss=0.4613*, v_f1=0.9678*
05/05 03:57:21 [INFO] eps=3, lr=1.45e-05, t_loss=0.5571, v_loss=0.4633 , v_f1=0.9664 
05/05 03:58:44 [INFO] eps=4, lr=1.35e-05, t_loss=0.5327, v_loss=0.4618 , v_f1=0.9668 
05/05 04:00:07 [INFO] eps=4, lr=1.25e-05, t_loss=0.5272, v_loss=0.4575*, v_f1=0.9671 
05/05 04:01:31 [INFO] eps=4, lr=1.17e-05, t_loss=0.5244, v_loss=0.4523*, v_f1=0.9693*
05/05 04:02:54 [INFO] eps=4, lr=1.08e-05, t_loss=0.5212, v_loss=0.4551 , v_f1=0.9661 
05/05 04:04:17 [INFO] eps=5, lr=1.01e-05, t_loss=0.5004, v_loss=0.4500*, v_f1=0.9681 
05/05 04:05:41 [INFO] eps=5, lr=9.38e-06, t_loss=0.4985, v_loss=0.4520 , v_f1=0.9696*
05/05 04:07:04 [INFO] eps=5, lr=8.73e-06, t_loss=0.5021, v_loss=0.4488*, v_f1=0.9692 
05/05 04:08:27 [INFO] eps=5, lr=8.11e-06, t_loss=0.5007, v_loss=0.4473*, v_f1=0.9692 
05/05 04:09:50 [INFO] eps=6, lr=7.55e-06, t_loss=0.4863, v_loss=0.4458*, v_f1=0.9702*
05/05 04:11:14 [INFO] eps=6, lr=7.02e-06, t_loss=0.4906, v_loss=0.4478 , v_f1=0.9696 
05/05 04:12:37 [INFO] eps=6, lr=6.53e-06, t_loss=0.4953, v_loss=0.4433*, v_f1=0.9718*
05/05 04:14:00 [INFO] eps=6, lr=6.07e-06, t_loss=0.4957, v_loss=0.4431*, v_f1=0.9702 
05/05 04:15:24 [INFO] eps=7, lr=5.65e-06, t_loss=0.4815, v_loss=0.4446 , v_f1=0.9690 
05/05 04:16:47 [INFO] eps=7, lr=5.25e-06, t_loss=0.4856, v_loss=0.4404*, v_f1=0.9714 
05/05 04:18:10 [INFO] eps=7, lr=4.88e-06, t_loss=0.4845, v_loss=0.4396*, v_f1=0.9721*
05/05 04:19:33 [INFO] eps=7, lr=4.54e-06, t_loss=0.4842, v_loss=0.4384*, v_f1=0.9734*
05/05 04:20:57 [INFO] eps=8, lr=4.22e-06, t_loss=0.4832, v_loss=0.4398 , v_f1=0.9729 
05/05 04:22:20 [INFO] eps=8, lr=3.93e-06, t_loss=0.4743, v_loss=0.4376*, v_f1=0.9727 
05/05 04:23:43 [INFO] eps=8, lr=3.65e-06, t_loss=0.4807, v_loss=0.4387 , v_f1=0.9715 
05/05 04:25:07 [INFO] eps=8, lr=3.4e-06, t_loss=0.4803, v_loss=0.4367*, v_f1=0.9728 
05/05 04:26:30 [INFO] eps=9, lr=3.16e-06, t_loss=0.4851, v_loss=0.4389 , v_f1=0.9733 
05/05 04:27:54 [INFO] eps=9, lr=2.94e-06, t_loss=0.4798, v_loss=0.4364*, v_f1=0.9735*
05/05 04:29:17 [INFO] eps=9, lr=2.73e-06, t_loss=0.4786, v_loss=0.4349*, v_f1=0.9747*
05/05 04:30:40 [INFO] eps=9, lr=2.54e-06, t_loss=0.4746, v_loss=0.4366 , v_f1=0.9738 
05/05 04:32:04 [INFO] eps=10, lr=2.36e-06, t_loss=0.4647, v_loss=0.4376 , v_f1=0.9738 
05/05 04:33:27 [INFO] eps=10, lr=2.2e-06, t_loss=0.4716, v_loss=0.4374 , v_f1=0.9728 
05/05 04:34:51 [INFO] eps=10, lr=2.04e-06, t_loss=0.4728, v_loss=0.4356 , v_f1=0.9741 
05/05 04:36:14 [INFO] eps=10, lr=1.9e-06, t_loss=0.4714, v_loss=0.4365 , v_f1=0.9732 
05/05 04:37:38 [INFO] eps=11, lr=1.77e-06, t_loss=0.4585, v_loss=0.4359 , v_f1=0.9746 
05/05 04:37:38 [INFO] NO_MORE_TRAINING, best_score=0.9747
05/05 04:37:57 [INFO] EMA ::: ema_v_loss=0.4369, ema_v_f1=0.9737
05/05 04:37:58 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=1-epoch=11-val_loss=0.4369-val_score=0.9737-ema.ckpt : (ema) saved.
05/05 04:37:59 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=1-epoch=09-val_loss=0.4349-val_score=0.9747.ckpt : saved.
05/05 04:38:00 [INFO] fold_idx=1 finished
05/05 04:38:06 [INFO] fold_idx=2 started
05/05 04:38:13 [INFO] load_img_size=224
05/05 04:38:13 [INFO] load_img_size=224
05/05 04:38:13 [INFO] create_model: timm/deit3_large_patch16_224.fb_in22k_ft_in1k
05/05 04:38:13 [INFO] Loading pretrained weights from Hugging Face hub (timm/deit3_large_patch16_224.fb_in22k_ft_in1k)
05/05 04:38:13 [INFO] [timm/deit3_large_patch16_224.fb_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
05/05 04:38:14 [INFO] use_amp=True
05/05 04:39:37 [INFO] eps=1, lr=3.22e-05, t_loss=2.0805, v_loss=1.0859*, v_f1=0.8666*
05/05 04:41:00 [INFO] eps=1, lr=3e-05, t_loss=1.4902, v_loss=0.5791*, v_f1=0.9441*
05/05 04:42:24 [INFO] eps=1, lr=2.79e-05, t_loss=1.2455, v_loss=0.5421*, v_f1=0.9519*
05/05 04:43:47 [INFO] eps=1, lr=2.59e-05, t_loss=1.1088, v_loss=0.5128*, v_f1=0.9602*
05/05 04:45:11 [INFO] eps=2, lr=2.41e-05, t_loss=0.6227, v_loss=0.5010*, v_f1=0.9663*
05/05 04:46:35 [INFO] eps=2, lr=2.24e-05, t_loss=0.6182, v_loss=0.4936*, v_f1=0.9655 
05/05 04:47:58 [INFO] eps=2, lr=2.08e-05, t_loss=0.6189, v_loss=0.4837*, v_f1=0.9665*
05/05 04:49:22 [INFO] eps=2, lr=1.94e-05, t_loss=0.6135, v_loss=0.4813*, v_f1=0.9650 
05/05 04:50:45 [INFO] eps=3, lr=1.8e-05, t_loss=0.5690, v_loss=0.4725*, v_f1=0.9685*
05/05 04:52:09 [INFO] eps=3, lr=1.68e-05, t_loss=0.5648, v_loss=0.4700*, v_f1=0.9673 
05/05 04:53:32 [INFO] eps=3, lr=1.56e-05, t_loss=0.5667, v_loss=0.4685*, v_f1=0.9693*
05/05 04:54:56 [INFO] eps=3, lr=1.45e-05, t_loss=0.5579, v_loss=0.4640*, v_f1=0.9692 
05/05 04:56:19 [INFO] eps=4, lr=1.35e-05, t_loss=0.5266, v_loss=0.4612*, v_f1=0.9698*
05/05 04:57:42 [INFO] eps=4, lr=1.25e-05, t_loss=0.5229, v_loss=0.4608*, v_f1=0.9694 
05/05 04:59:06 [INFO] eps=4, lr=1.17e-05, t_loss=0.5186, v_loss=0.4602*, v_f1=0.9681 
05/05 05:00:29 [INFO] eps=4, lr=1.08e-05, t_loss=0.5210, v_loss=0.4600*, v_f1=0.9687 
05/05 05:01:53 [INFO] eps=5, lr=1.01e-05, t_loss=0.5229, v_loss=0.4574*, v_f1=0.9683 
05/05 05:03:16 [INFO] eps=5, lr=9.38e-06, t_loss=0.5186, v_loss=0.4540*, v_f1=0.9693 
05/05 05:04:40 [INFO] eps=5, lr=8.73e-06, t_loss=0.5150, v_loss=0.4501*, v_f1=0.9722*
05/05 05:06:03 [INFO] eps=5, lr=8.11e-06, t_loss=0.5134, v_loss=0.4496*, v_f1=0.9708 
05/05 05:07:26 [INFO] eps=6, lr=7.55e-06, t_loss=0.5097, v_loss=0.4506 , v_f1=0.9704 
05/05 05:08:50 [INFO] eps=6, lr=7.02e-06, t_loss=0.5007, v_loss=0.4471*, v_f1=0.9723*
05/05 05:10:14 [INFO] eps=6, lr=6.53e-06, t_loss=0.4956, v_loss=0.4468*, v_f1=0.9699 
05/05 05:11:38 [INFO] eps=6, lr=6.07e-06, t_loss=0.4928, v_loss=0.4481 , v_f1=0.9695 
05/05 05:13:01 [INFO] eps=7, lr=5.65e-06, t_loss=0.4831, v_loss=0.4456*, v_f1=0.9713 
05/05 05:14:24 [INFO] eps=7, lr=5.25e-06, t_loss=0.4830, v_loss=0.4450*, v_f1=0.9725*
05/05 05:15:48 [INFO] eps=7, lr=4.88e-06, t_loss=0.4877, v_loss=0.4457 , v_f1=0.9717 
05/05 05:17:11 [INFO] eps=7, lr=4.54e-06, t_loss=0.4856, v_loss=0.4457 , v_f1=0.9698 
05/05 05:18:35 [INFO] eps=8, lr=4.22e-06, t_loss=0.4750, v_loss=0.4459 , v_f1=0.9699 
05/05 05:19:58 [INFO] eps=8, lr=3.93e-06, t_loss=0.4715, v_loss=0.4438*, v_f1=0.9711 
05/05 05:21:22 [INFO] eps=8, lr=3.65e-06, t_loss=0.4747, v_loss=0.4439 , v_f1=0.9707 
05/05 05:22:46 [INFO] eps=8, lr=3.4e-06, t_loss=0.4703, v_loss=0.4423*, v_f1=0.9713 
05/05 05:24:09 [INFO] eps=9, lr=3.16e-06, t_loss=0.4881, v_loss=0.4442 , v_f1=0.9708 
05/05 05:25:33 [INFO] eps=9, lr=2.94e-06, t_loss=0.4840, v_loss=0.4424 , v_f1=0.9714 
05/05 05:26:57 [INFO] eps=9, lr=2.73e-06, t_loss=0.4834, v_loss=0.4419*, v_f1=0.9707 
05/05 05:28:20 [INFO] eps=9, lr=2.54e-06, t_loss=0.4816, v_loss=0.4426 , v_f1=0.9714 
05/05 05:29:44 [INFO] eps=10, lr=2.36e-06, t_loss=0.4740, v_loss=0.4439 , v_f1=0.9704 
05/05 05:31:07 [INFO] eps=10, lr=2.2e-06, t_loss=0.4730, v_loss=0.4420 , v_f1=0.9720 
05/05 05:32:31 [INFO] eps=10, lr=2.04e-06, t_loss=0.4775, v_loss=0.4419*, v_f1=0.9718 
05/05 05:33:55 [INFO] eps=10, lr=1.9e-06, t_loss=0.4769, v_loss=0.4410*, v_f1=0.9734*
05/05 05:35:18 [INFO] eps=11, lr=1.77e-06, t_loss=0.4603, v_loss=0.4416 , v_f1=0.9714 
05/05 05:36:42 [INFO] eps=11, lr=1.64e-06, t_loss=0.4731, v_loss=0.4409*, v_f1=0.9717 
05/05 05:38:06 [INFO] eps=11, lr=1.53e-06, t_loss=0.4816, v_loss=0.4406*, v_f1=0.9724 
05/05 05:39:30 [INFO] eps=11, lr=1.42e-06, t_loss=0.4760, v_loss=0.4397*, v_f1=0.9730 
05/05 05:40:53 [INFO] eps=12, lr=1.32e-06, t_loss=0.4615, v_loss=0.4391*, v_f1=0.9732 
05/05 05:42:17 [INFO] eps=12, lr=1.23e-06, t_loss=0.4679, v_loss=0.4390*, v_f1=0.9733 
05/05 05:43:41 [INFO] eps=12, lr=1.14e-06, t_loss=0.4692, v_loss=0.4395 , v_f1=0.9720 
05/05 05:45:05 [INFO] eps=12, lr=1.06e-06, t_loss=0.4723, v_loss=0.4394 , v_f1=0.9726 
05/05 05:46:28 [INFO] eps=13, lr=9.89e-07, t_loss=0.4752, v_loss=0.4391 , v_f1=0.9715 
05/05 05:47:52 [INFO] eps=13, lr=9.2e-07, t_loss=0.4760, v_loss=0.4391 , v_f1=0.9726 
05/05 05:49:16 [INFO] eps=13, lr=8.56e-07, t_loss=0.4707, v_loss=0.4389*, v_f1=0.9726 
05/05 05:50:41 [INFO] eps=13, lr=7.96e-07, t_loss=0.4679, v_loss=0.4393 , v_f1=0.9723 
05/05 05:52:05 [INFO] eps=14, lr=7.4e-07, t_loss=0.4632, v_loss=0.4390 , v_f1=0.9720 
05/05 05:53:30 [INFO] eps=14, lr=6.88e-07, t_loss=0.4659, v_loss=0.4388*, v_f1=0.9723 
05/05 05:54:54 [INFO] eps=14, lr=6.4e-07, t_loss=0.4633, v_loss=0.4388 , v_f1=0.9720 
05/05 05:56:18 [INFO] eps=14, lr=5.95e-07, t_loss=0.4651, v_loss=0.4389 , v_f1=0.9723 
05/05 05:57:42 [INFO] eps=15, lr=5.54e-07, t_loss=0.4661, v_loss=0.4388 , v_f1=0.9713 
05/05 05:59:06 [INFO] eps=15, lr=5.15e-07, t_loss=0.4676, v_loss=0.4390 , v_f1=0.9713 
05/05 06:00:30 [INFO] eps=15, lr=4.79e-07, t_loss=0.4651, v_loss=0.4392 , v_f1=0.9716 
05/05 06:01:53 [INFO] eps=15, lr=4.45e-07, t_loss=0.4629, v_loss=0.4389 , v_f1=0.9716 
05/05 06:01:53 [INFO] NO_MORE_TRAINING, best_score=0.9734
05/05 06:02:12 [INFO] EMA ::: ema_v_loss=0.4391, ema_v_f1=0.9710
05/05 06:02:14 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=2-epoch=15-val_loss=0.4391-val_score=0.9710-ema.ckpt : (ema) saved.
05/05 06:02:15 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=2-epoch=10-val_loss=0.4410-val_score=0.9734.ckpt : saved.
05/05 06:02:15 [INFO] fold_idx=2 finished
05/05 06:02:23 [INFO] fold_idx=3 started
05/05 06:02:30 [INFO] load_img_size=224
05/05 06:02:30 [INFO] load_img_size=224
05/05 06:02:30 [INFO] create_model: timm/deit3_large_patch16_224.fb_in22k_ft_in1k
05/05 06:02:30 [INFO] Loading pretrained weights from Hugging Face hub (timm/deit3_large_patch16_224.fb_in22k_ft_in1k)
05/05 06:02:30 [INFO] [timm/deit3_large_patch16_224.fb_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
05/05 06:02:31 [INFO] use_amp=True
05/05 06:03:54 [INFO] eps=1, lr=3.22e-05, t_loss=1.9302, v_loss=0.8636*, v_f1=0.9012*
05/05 06:05:19 [INFO] eps=1, lr=3e-05, t_loss=1.4153, v_loss=0.5441*, v_f1=0.9547*
05/05 06:06:43 [INFO] eps=1, lr=2.79e-05, t_loss=1.1867, v_loss=0.5131*, v_f1=0.9609*
05/05 06:08:07 [INFO] eps=1, lr=2.59e-05, t_loss=1.0641, v_loss=0.4927*, v_f1=0.9649*
05/05 06:09:31 [INFO] eps=2, lr=2.41e-05, t_loss=0.6337, v_loss=0.4793*, v_f1=0.9692*
05/05 06:10:55 [INFO] eps=2, lr=2.24e-05, t_loss=0.6358, v_loss=0.4750*, v_f1=0.9673 
05/05 06:12:20 [INFO] eps=2, lr=2.08e-05, t_loss=0.6306, v_loss=0.4667*, v_f1=0.9727*
05/05 06:13:43 [INFO] eps=2, lr=1.94e-05, t_loss=0.6198, v_loss=0.4625*, v_f1=0.9725 
05/05 06:15:07 [INFO] eps=3, lr=1.8e-05, t_loss=0.5605, v_loss=0.4566*, v_f1=0.9729*
05/05 06:16:31 [INFO] eps=3, lr=1.68e-05, t_loss=0.5602, v_loss=0.4550*, v_f1=0.9732*
05/05 06:17:55 [INFO] eps=3, lr=1.56e-05, t_loss=0.5612, v_loss=0.4534*, v_f1=0.9732 
05/05 06:19:18 [INFO] eps=3, lr=1.45e-05, t_loss=0.5586, v_loss=0.4473*, v_f1=0.9742*
05/05 06:20:42 [INFO] eps=4, lr=1.35e-05, t_loss=0.5500, v_loss=0.4465*, v_f1=0.9742 
05/05 06:22:06 [INFO] eps=4, lr=1.25e-05, t_loss=0.5404, v_loss=0.4424*, v_f1=0.9735 
05/05 06:23:30 [INFO] eps=4, lr=1.17e-05, t_loss=0.5366, v_loss=0.4423*, v_f1=0.9736 
05/05 06:24:54 [INFO] eps=4, lr=1.08e-05, t_loss=0.5297, v_loss=0.4415*, v_f1=0.9764*
05/05 06:24:55 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=3-epoch=04-val_loss=0.4415-val_score=0.9764.ckpt : saved.
05/05 06:26:19 [INFO] eps=5, lr=1.01e-05, t_loss=0.5008, v_loss=0.4430 , v_f1=0.9749 
05/05 06:27:43 [INFO] eps=5, lr=9.38e-06, t_loss=0.5036, v_loss=0.4395*, v_f1=0.9760 
05/05 06:29:07 [INFO] eps=5, lr=8.73e-06, t_loss=0.5122, v_loss=0.4387*, v_f1=0.9753 
05/05 06:30:31 [INFO] eps=5, lr=8.11e-06, t_loss=0.5109, v_loss=0.4351*, v_f1=0.9776*
05/05 06:30:32 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=3-epoch=05-val_loss=0.4351-val_score=0.9776.ckpt : saved.
05/05 06:31:56 [INFO] eps=6, lr=7.55e-06, t_loss=0.4974, v_loss=0.4336*, v_f1=0.9752 
05/05 06:33:20 [INFO] eps=6, lr=7.02e-06, t_loss=0.4936, v_loss=0.4309*, v_f1=0.9790*
05/05 06:33:21 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=3-epoch=06-val_loss=0.4309-val_score=0.9790.ckpt : saved.
05/05 06:34:46 [INFO] eps=6, lr=6.53e-06, t_loss=0.4897, v_loss=0.4339 , v_f1=0.9765 
05/05 06:36:09 [INFO] eps=6, lr=6.07e-06, t_loss=0.4925, v_loss=0.4306*, v_f1=0.9760 
05/05 06:37:33 [INFO] eps=7, lr=5.65e-06, t_loss=0.4732, v_loss=0.4306 , v_f1=0.9764 
05/05 06:38:57 [INFO] eps=7, lr=5.25e-06, t_loss=0.4772, v_loss=0.4295*, v_f1=0.9776 
05/05 06:40:21 [INFO] eps=7, lr=4.88e-06, t_loss=0.4783, v_loss=0.4279*, v_f1=0.9783 
05/05 06:41:45 [INFO] eps=7, lr=4.54e-06, t_loss=0.4798, v_loss=0.4293 , v_f1=0.9770 
05/05 06:43:09 [INFO] eps=8, lr=4.22e-06, t_loss=0.4839, v_loss=0.4293 , v_f1=0.9783 
05/05 06:44:32 [INFO] eps=8, lr=3.93e-06, t_loss=0.4820, v_loss=0.4286 , v_f1=0.9774 
05/05 06:45:56 [INFO] eps=8, lr=3.65e-06, t_loss=0.4849, v_loss=0.4292 , v_f1=0.9787 
05/05 06:47:20 [INFO] eps=8, lr=3.4e-06, t_loss=0.4843, v_loss=0.4273*, v_f1=0.9778 
05/05 06:48:43 [INFO] eps=9, lr=3.16e-06, t_loss=0.4872, v_loss=0.4275 , v_f1=0.9771 
05/05 06:50:07 [INFO] eps=9, lr=2.94e-06, t_loss=0.4808, v_loss=0.4276 , v_f1=0.9780 
05/05 06:51:31 [INFO] eps=9, lr=2.73e-06, t_loss=0.4796, v_loss=0.4284 , v_f1=0.9771 
05/05 06:52:55 [INFO] eps=9, lr=2.54e-06, t_loss=0.4778, v_loss=0.4264*, v_f1=0.9786 
05/05 06:54:19 [INFO] eps=10, lr=2.36e-06, t_loss=0.4685, v_loss=0.4275 , v_f1=0.9775 
05/05 06:55:43 [INFO] eps=10, lr=2.2e-06, t_loss=0.4692, v_loss=0.4266 , v_f1=0.9773 
05/05 06:57:06 [INFO] eps=10, lr=2.04e-06, t_loss=0.4730, v_loss=0.4265 , v_f1=0.9770 
05/05 06:58:30 [INFO] eps=10, lr=1.9e-06, t_loss=0.4756, v_loss=0.4261*, v_f1=0.9767 
05/05 06:59:54 [INFO] eps=11, lr=1.77e-06, t_loss=0.4720, v_loss=0.4251*, v_f1=0.9793*
05/05 06:59:55 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=3-epoch=11-val_loss=0.4251-val_score=0.9793.ckpt : saved.
05/05 07:01:19 [INFO] eps=11, lr=1.64e-06, t_loss=0.4706, v_loss=0.4256 , v_f1=0.9779 
05/05 07:02:43 [INFO] eps=11, lr=1.53e-06, t_loss=0.4703, v_loss=0.4246*, v_f1=0.9795*
05/05 07:02:44 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=3-epoch=11-val_loss=0.4246-val_score=0.9795.ckpt : saved.
05/05 07:04:08 [INFO] eps=11, lr=1.42e-06, t_loss=0.4714, v_loss=0.4252 , v_f1=0.9789 
05/05 07:05:32 [INFO] eps=12, lr=1.32e-06, t_loss=0.4687, v_loss=0.4248 , v_f1=0.9793 
05/05 07:06:55 [INFO] eps=12, lr=1.23e-06, t_loss=0.4641, v_loss=0.4244*, v_f1=0.9786 
05/05 07:08:19 [INFO] eps=12, lr=1.14e-06, t_loss=0.4655, v_loss=0.4245 , v_f1=0.9783 
05/05 07:09:43 [INFO] eps=12, lr=1.06e-06, t_loss=0.4677, v_loss=0.4242*, v_f1=0.9786 
05/05 07:11:07 [INFO] eps=13, lr=9.89e-07, t_loss=0.4709, v_loss=0.4244 , v_f1=0.9785 
05/05 07:12:31 [INFO] eps=13, lr=9.2e-07, t_loss=0.4650, v_loss=0.4249 , v_f1=0.9767 
05/05 07:13:54 [INFO] eps=13, lr=8.56e-07, t_loss=0.4655, v_loss=0.4253 , v_f1=0.9770 
05/05 07:15:18 [INFO] eps=13, lr=7.96e-07, t_loss=0.4687, v_loss=0.4247 , v_f1=0.9773 
05/05 07:16:42 [INFO] eps=14, lr=7.4e-07, t_loss=0.4624, v_loss=0.4243 , v_f1=0.9770 
05/05 07:18:06 [INFO] eps=14, lr=6.88e-07, t_loss=0.4737, v_loss=0.4244 , v_f1=0.9770 
05/05 07:18:06 [INFO] NO_MORE_TRAINING, best_score=0.9795
05/05 07:18:25 [INFO] EMA ::: ema_v_loss=0.4248, ema_v_f1=0.9770
05/05 07:18:26 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=3-epoch=14-val_loss=0.4248-val_score=0.9770-ema.ckpt : (ema) saved.
05/05 07:18:27 [INFO] fold_idx=3 finished
05/05 07:18:33 [INFO] fold_idx=4 started
05/05 07:18:40 [INFO] load_img_size=224
05/05 07:18:40 [INFO] load_img_size=224
05/05 07:18:40 [INFO] create_model: timm/deit3_large_patch16_224.fb_in22k_ft_in1k
05/05 07:18:41 [INFO] Loading pretrained weights from Hugging Face hub (timm/deit3_large_patch16_224.fb_in22k_ft_in1k)
05/05 07:18:41 [INFO] [timm/deit3_large_patch16_224.fb_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
05/05 07:18:41 [INFO] use_amp=True
05/05 07:20:05 [INFO] eps=1, lr=3.22e-05, t_loss=1.9130, v_loss=0.8928*, v_f1=0.8881*
05/05 07:21:29 [INFO] eps=1, lr=3e-05, t_loss=1.3805, v_loss=0.5621*, v_f1=0.9489*
05/05 07:22:53 [INFO] eps=1, lr=2.79e-05, t_loss=1.1645, v_loss=0.5250*, v_f1=0.9558*
05/05 07:24:17 [INFO] eps=1, lr=2.59e-05, t_loss=1.0434, v_loss=0.5093*, v_f1=0.9579*
05/05 07:25:41 [INFO] eps=2, lr=2.41e-05, t_loss=0.6482, v_loss=0.4911*, v_f1=0.9638*
05/05 07:27:05 [INFO] eps=2, lr=2.24e-05, t_loss=0.6214, v_loss=0.4759*, v_f1=0.9654*
05/05 07:28:29 [INFO] eps=2, lr=2.08e-05, t_loss=0.6174, v_loss=0.4671*, v_f1=0.9663*
05/05 07:29:53 [INFO] eps=2, lr=1.94e-05, t_loss=0.6106, v_loss=0.4673 , v_f1=0.9677*
05/05 07:31:17 [INFO] eps=3, lr=1.8e-05, t_loss=0.5461, v_loss=0.4628*, v_f1=0.9684*
05/05 07:32:40 [INFO] eps=3, lr=1.68e-05, t_loss=0.5624, v_loss=0.4623*, v_f1=0.9712*
05/05 07:34:04 [INFO] eps=3, lr=1.56e-05, t_loss=0.5550, v_loss=0.4614*, v_f1=0.9687 
05/05 07:35:27 [INFO] eps=3, lr=1.45e-05, t_loss=0.5491, v_loss=0.4532*, v_f1=0.9694 
05/05 07:36:51 [INFO] eps=4, lr=1.35e-05, t_loss=0.5363, v_loss=0.4546 , v_f1=0.9698 
05/05 07:38:15 [INFO] eps=4, lr=1.25e-05, t_loss=0.5342, v_loss=0.4441*, v_f1=0.9731*
05/05 07:39:38 [INFO] eps=4, lr=1.17e-05, t_loss=0.5322, v_loss=0.4435*, v_f1=0.9720 
05/05 07:41:02 [INFO] eps=4, lr=1.08e-05, t_loss=0.5320, v_loss=0.4432*, v_f1=0.9734*
05/05 07:42:26 [INFO] eps=5, lr=1.01e-05, t_loss=0.5172, v_loss=0.4426*, v_f1=0.9725 
05/05 07:43:50 [INFO] eps=5, lr=9.38e-06, t_loss=0.5090, v_loss=0.4445 , v_f1=0.9724 
05/05 07:45:14 [INFO] eps=5, lr=8.73e-06, t_loss=0.5082, v_loss=0.4453 , v_f1=0.9729 
05/05 07:46:37 [INFO] eps=5, lr=8.11e-06, t_loss=0.5084, v_loss=0.4419*, v_f1=0.9726 
05/05 07:48:01 [INFO] eps=6, lr=7.55e-06, t_loss=0.5123, v_loss=0.4416*, v_f1=0.9750*
05/05 07:48:02 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=4-epoch=06-val_loss=0.4416-val_score=0.9750.ckpt : saved.
05/05 07:49:26 [INFO] eps=6, lr=7.02e-06, t_loss=0.5080, v_loss=0.4417 , v_f1=0.9738 
05/05 07:50:49 [INFO] eps=6, lr=6.53e-06, t_loss=0.4945, v_loss=0.4401*, v_f1=0.9744 
05/05 07:52:13 [INFO] eps=6, lr=6.07e-06, t_loss=0.4938, v_loss=0.4383*, v_f1=0.9741 
05/05 07:53:36 [INFO] eps=7, lr=5.65e-06, t_loss=0.4875, v_loss=0.4382*, v_f1=0.9741 
05/05 07:55:00 [INFO] eps=7, lr=5.25e-06, t_loss=0.4967, v_loss=0.4381*, v_f1=0.9747 
05/05 07:56:24 [INFO] eps=7, lr=4.88e-06, t_loss=0.4881, v_loss=0.4391 , v_f1=0.9740 
05/05 07:57:47 [INFO] eps=7, lr=4.54e-06, t_loss=0.4874, v_loss=0.4379*, v_f1=0.9746 
05/05 07:59:11 [INFO] eps=8, lr=4.22e-06, t_loss=0.4797, v_loss=0.4363*, v_f1=0.9756*
05/05 07:59:12 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=4-epoch=08-val_loss=0.4363-val_score=0.9756.ckpt : saved.
05/05 08:00:36 [INFO] eps=8, lr=3.93e-06, t_loss=0.4847, v_loss=0.4344*, v_f1=0.9774*
05/05 08:00:37 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=4-epoch=08-val_loss=0.4344-val_score=0.9774.ckpt : saved.
05/05 08:02:00 [INFO] eps=8, lr=3.65e-06, t_loss=0.4835, v_loss=0.4338*, v_f1=0.9756 
05/05 08:03:24 [INFO] eps=8, lr=3.4e-06, t_loss=0.4814, v_loss=0.4353 , v_f1=0.9759 
05/05 08:04:48 [INFO] eps=9, lr=3.16e-06, t_loss=0.4687, v_loss=0.4351 , v_f1=0.9759 
05/05 08:06:12 [INFO] eps=9, lr=2.94e-06, t_loss=0.4723, v_loss=0.4349 , v_f1=0.9752 
05/05 08:07:36 [INFO] eps=9, lr=2.73e-06, t_loss=0.4753, v_loss=0.4350 , v_f1=0.9740 
05/05 08:08:59 [INFO] eps=9, lr=2.54e-06, t_loss=0.4749, v_loss=0.4340 , v_f1=0.9762 
05/05 08:10:23 [INFO] eps=10, lr=2.36e-06, t_loss=0.4787, v_loss=0.4345 , v_f1=0.9760 
05/05 08:10:23 [INFO] NO_MORE_TRAINING, best_score=0.9774
05/05 08:10:43 [INFO] EMA ::: ema_v_loss=0.4347, ema_v_f1=0.9756
05/05 08:10:44 [INFO] ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1k-fold_idx=4-epoch=10-val_loss=0.4347-val_score=0.9756-ema.ckpt : (ema) saved.
05/05 08:10:44 [INFO] fold_idx=4 finished